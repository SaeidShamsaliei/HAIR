{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b19ec032-cbd5-4bee-93dd-91c849a41486",
   "metadata": {},
   "source": [
    "to investigate how to zoom out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fddb6b8b-5813-4aef-8c81-6523388d2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5713a70-9d45-46e4-91fb-c596dea1adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the inputs\n",
    "# %autoreload\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from costum_arild.source import data_processing\n",
    "from costum_arild.source.data_processing import TrainingImage\n",
    "from costum_arild.source.utils import image_processing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a0e9c8-c4fe-4923-9613-5ebe0ef16854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_image_add_channel(image_filepath, label_filepath, image_size=512, do_overlap=False, do_crop=False, add_filter_channel=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    add_filter_channel: indicate if we want to have filters as external channels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load image\n",
    "    image_ds = gdal.Open(image_filepath)\n",
    "    geo_transform = image_ds.GetGeoTransform()\n",
    "    projection = image_ds.GetProjection()\n",
    "    # check the number of rasters\n",
    "    image_matrix = np.array(([image_ds.GetRasterBand(band_idx+1).ReadAsArray() for band_idx in range(image_ds.RasterCount)]))\n",
    "    if len(image_matrix.shape) > 2:\n",
    "        # get (x,y, channel) form\n",
    "        image_matrix = np.transpose(image_matrix, axes=[1, 2, 0])\n",
    "    \n",
    "    # this part is different since we want to have Gray scale\n",
    "    from PIL import Image\n",
    "    image_matrix = np.array(Image.fromarray(image_matrix).convert('L'))\n",
    "    image_ds = None\n",
    "    \n",
    "\n",
    "    # Load label\n",
    "    label_ds = gdal.Open(label_filepath)\n",
    "    if label_ds.GetGeoTransform() != geo_transform:\n",
    "        raise Exception(f\"The geo transforms of image {image_filepath} and label {label_filepath} did not match\")\n",
    "    label_matrix = label_ds.GetRasterBand(1).ReadAsArray()\n",
    "    label_ds = None\n",
    "\n",
    "    training_data = []\n",
    "    # Make properly sized training data\n",
    "    # Make sure that the whole image is covered, even if the last one has to overlap\n",
    "    if do_overlap:\n",
    "        shape_0_indices = list(range(image_size // 4, image_matrix.shape[0], image_size // 4))[:-4]\n",
    "        shape_1_indices = list(range(image_size // 4, image_matrix.shape[1], image_size // 4))[:-4]\n",
    "    else:\n",
    "        shape_0_indices = list(range(0, image_matrix.shape[0], image_size))\n",
    "        shape_0_indices[-1] = image_matrix.shape[0] - image_size\n",
    "        shape_1_indices = list(range(0, image_matrix.shape[1], image_size))\n",
    "        shape_1_indices[-1] = image_matrix.shape[1] - image_size\n",
    "    # Split the images\n",
    "    for shape_0 in shape_0_indices:\n",
    "        for shape_1 in shape_1_indices:\n",
    "            if do_crop:\n",
    "                # Extract labels for the center of the image\n",
    "                labels = label_matrix[shape_0 + image_size // 4:shape_0 + image_size - image_size // 4,\n",
    "                         shape_1 + image_size // 4:shape_1 + image_size - image_size // 4]\n",
    "            else:\n",
    "                labels = label_matrix[shape_0:shape_0 + image_size, shape_1:shape_1 + image_size]\n",
    "            # Check if the image has to much unknown\n",
    "            if not data_processing.is_quality_image(labels):\n",
    "                continue\n",
    "\n",
    "            # Calculate the geo transform of the label\n",
    "            label_geo_transform = list(geo_transform)\n",
    "            if do_crop:\n",
    "                label_geo_transform[0] += (shape_1 + image_size//4) * geo_transform[1]  # East\n",
    "                label_geo_transform[3] += (shape_0 + image_size//4) * geo_transform[5]  # North\n",
    "            else:\n",
    "                label_geo_transform[0] += (shape_1) * geo_transform[1]  # East\n",
    "                label_geo_transform[3] += (shape_0) * geo_transform[5]  # North\n",
    "\n",
    "            data = image_matrix[shape_0:shape_0 + image_size, shape_1:shape_1 + image_size]\n",
    "            filter_channel = image_processing_utils.qshitf_boundary(data, ratio=0.9)\n",
    "            cluster_channel = image_processing_utils.laplacian_filter(data, sigma=5)\n",
    "            \n",
    "            data_3d = np.stack([data, filter_channel, cluster_channel], axis=-1)\n",
    "            \n",
    "            new_data_geo_transform = list(geo_transform)\n",
    "            new_data_geo_transform[0] += shape_1 * geo_transform[1]  # East\n",
    "            new_data_geo_transform[3] += shape_0 * geo_transform[5]  # North\n",
    "\n",
    "            name = os.path.split(image_filepath)[-1].replace(\".tif\", \"\") + f\"_n_{shape_0}_e_{shape_1}\"\n",
    "            training_data.append(TrainingImage(data_3d, labels, new_data_geo_transform, name=name, projection=projection,\n",
    "                                               label_geo_transform=label_geo_transform, east_offset=shape_1,\n",
    "                                               north_offset=shape_0))\n",
    "    return training_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
