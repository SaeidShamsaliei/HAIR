{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366c8614",
   "metadata": {},
   "source": [
    "this notebook, prepares the dataset for magnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20030cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45214953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 11:17:17.169655: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import time\n",
    "from scipy import ndimage, signal\n",
    "from cv2 import medianBlur\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from PIL import Image\n",
    "from costum_arild.source.utils import image_processing_utils, gdal_utils\n",
    "from costum_arild.source.data_processing import TrainingImage\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ce8d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = 'river_deepglobe'\n",
    "# base_dataset_path = f'/home/saeid/phd/segmentation/MagNet-main/data/{dataset}'\n",
    "# img_path = os.path.join(base_dataset_path, 'image')\n",
    "# lbl_path = os.path.join(base_dataset_path, 'label')\n",
    "# list_path = f'/home/saeid/phd/segmentation/MagNet-main/data/list/{dataset}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2a59e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dataset_path = f'/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/all_train_png/{dataset}\n",
    "dataset = 'hair_magnet_v1'\n",
    "base_dataset_path = f'/media/saeid/LaCie/arild_code/{dataset}'\n",
    "img_path = os.path.join(base_dataset_path, 'image')\n",
    "lbl_path = os.path.join(base_dataset_path, 'label')\n",
    "# list_path = f'/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/all_train_png/{dataset}'\n",
    "list_path = f'/media/saeid/LaCie/arild_code/{dataset}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6be8d4",
   "metadata": {},
   "source": [
    "change 2d to 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "866bc8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "867\n"
     ]
    }
   ],
   "source": [
    "# read the label\n",
    "\n",
    "# input type can be tif or png\n",
    "input_type = 'png' # or 'png'\n",
    "\n",
    "lbl_new_path = os.path.join(base_dataset_path, 'label_3d')\n",
    "os.makedirs(lbl_new_path, exist_ok=True)\n",
    "\n",
    "label_list = glob.glob(os.path.join(lbl_path, f'*.{input_type}'))\n",
    "for idx, label_path in enumerate(label_list):\n",
    "    label_name = os.path.split(label_path)[-1]\n",
    "    if input_type == 'png':\n",
    "        lbl_arr = image_processing_utils.read_png_file(label_path)\n",
    "    \n",
    "    elif input_type == 'tif':\n",
    "        lbl_arr = image_processing_utils.read_tiff_file(large_image_path = label_path, \n",
    "                                                        normalize=False, \n",
    "                                                        zeropadsize=None, \n",
    "                                                        numpy_array_only=True, \n",
    "                                                        grayscale_only=False)\n",
    "    else:\n",
    "        print('the input_type is not correct')\n",
    "        \n",
    "    lbl_arr = image_processing_utils.label_to_rgb(label_2d=lbl_arr, \n",
    "                                                  unknown_zero_flag=True, \n",
    "                                                  most_distant=False)\n",
    "    lbl_arr = np.squeeze(lbl_arr)\n",
    "    \n",
    "    image_processing_utils.save_to_png(\n",
    "        img_array=lbl_arr,\n",
    "        img_path=os.path.join(\n",
    "            lbl_new_path, label_name.replace('tif', 'png')),\n",
    "    )\n",
    "    if idx%1000 == 0:\n",
    "        print(idx)\n",
    "\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b2a0297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 8000, 1, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de38f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13446"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ca351",
   "metadata": {},
   "source": [
    "make the list of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85847759",
   "metadata": {},
   "source": [
    "Notice: label should be the actual label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81d5c53c-2a01-46f1-bfa1-926fbd02fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dataset_path = f'/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/all_train_png/{dataset}\n",
    "dataset = 'ML_G_2448'\n",
    "base_dataset_path = f'/media/saeid/LaCie/arild_code/{dataset}'\n",
    "img_path = os.path.join(base_dataset_path, 'image')\n",
    "lbl_path = os.path.join(base_dataset_path, 'label')\n",
    "# list_path = f'/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/all_train_png/{dataset}'\n",
    "list_path = f'/media/saeid/LaCie/arild_code/{dataset}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3afe416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the list of images and papers\n",
    "img_path_list = sorted(glob.glob(os.path.join(img_path, '*.png')))\n",
    "lbl_path_list = sorted(glob.glob(os.path.join(lbl_path, '*.png')))\n",
    "\n",
    "assert len(img_path_list) == len(img_path_list)\n",
    "\n",
    "indices = np.arange(len(img_path_list))\n",
    "np.random.shuffle(indices)\n",
    "len_train = int(0.8 * len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "449dd150",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = [img_path_list[idx] for idx in indices[:len_train]]\n",
    "train_lbl = [lbl_path_list[idx] for idx in indices[:len_train]]\n",
    "\n",
    "val_img = [img_path_list[idx] for idx in indices[len_train:]]\n",
    "val_lbl = [lbl_path_list[idx] for idx in indices[len_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd5e3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{val_img[0].split(dataset)[-1]}\\t{val_lbl[0].split(dataset)[-1]}\")\n",
    "os.makedirs(list_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(list_path, 'train.txt'), 'w') as f:\n",
    "    for idx, _ in enumerate(train_img):\n",
    "        assert os.path.split(train_img[idx])[-1] == os.path.split(train_lbl[idx])[-1]\n",
    "        f.write(f\"{train_img[idx].split(f'{dataset}/')[-1]}\\t{train_lbl[idx].split(f'{dataset}/')[-1]}\\n\")\n",
    "        \n",
    "with open(os.path.join(list_path, 'val.txt'), 'w') as f:\n",
    "    for idx, _ in enumerate(val_img):\n",
    "        assert os.path.split(val_img[idx])[-1] == os.path.split(val_lbl[idx])[-1]\n",
    "        f.write(f\"{val_img[idx].split(f'{dataset}/')[-1]}\\t{val_lbl[idx].split(f'{dataset}/')[-1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f599ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image/all_train_png_33-2-468-211-32.png_19_w.png\\tlabel/all_train_png_33-2-468-211-32.png_19_w.png\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{train_img[idx].split(f'{dataset}/')[-1]}\\t{train_lbl[idx].split(f'{dataset}/')[-1]}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f57c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
