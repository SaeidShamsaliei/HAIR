{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc0aff4-cec6-4f55-b6af-5d82340f3b33",
   "metadata": {},
   "source": [
    "# test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f799e475-c004-483f-a502-a36c1c152fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c0ff5b7-591d-40bb-952a-efbe8bf7cd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 13:51:03.055681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage, signal\n",
    "from cv2 import medianBlur\n",
    "import gdal\n",
    "from osgeo import ogr\n",
    "from osgeo import osr\n",
    "import tensorflow as tf\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from PIL import Image \n",
    "from costum_arild.source.utils import image_processing_utils, gdal_utils, notebook_utils, model_utils\n",
    "from costum_arild.source.data_processing import TrainingImage, divide_image, reassemble_big_image, reassemble_big_image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d1500d0-ca13-41ad-9965-7b0b15681b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(x, y, n, ignore_label=None, mask=None):\n",
    "    \"\"\"Compute confusion matrix\n",
    "\n",
    "    Args:\n",
    "        x (np.array): 1 x h x w\n",
    "            prediction array\n",
    "        y (np.array): 1 x h x w\n",
    "            groundtruth array\n",
    "        n (int): number of classes\n",
    "        ignore_label (int, optional): index of ignored label. Defaults to None.\n",
    "        mask (np.array, optional): mask of regions that is needed to compute. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        np.array: n x n\n",
    "            confusion matrix\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        mask = np.ones_like(x) == 1\n",
    "    k = (x >= 0) & (y < n) & (x != ignore_label) & (mask.astype(np.bool))\n",
    "    return np.bincount(n * x[k].astype(int) + y[k], minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "\n",
    "def getIoU(conf_matrix):\n",
    "    \"\"\"Compute IoU\n",
    "\n",
    "    Args:\n",
    "        conf_matrix (np.array): n x n\n",
    "            confusion matrix\n",
    "\n",
    "    Returns:\n",
    "        np.array: (n,)\n",
    "            IoU of classes\n",
    "    \"\"\"\n",
    "    if conf_matrix.sum() == 0:\n",
    "        return 0\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        union = np.maximum(1.0, conf_matrix.sum(axis=1) +\n",
    "                           conf_matrix.sum(axis=0) - np.diag(conf_matrix))\n",
    "        intersect = np.diag(conf_matrix)\n",
    "        IU = np.nan_to_num(intersect / union)\n",
    "    return IU\n",
    "\n",
    "\n",
    "def iou_single_class(labels, predictions, class_no):\n",
    "    \"\"\"\n",
    "    class should be number of classes\n",
    "    \"\"\"\n",
    "    labels_c = (labels == class_no)\n",
    "    pred_c = (predictions == class_no)\n",
    "    labels_c_sum = (labels_c).sum()\n",
    "    pred_c_sum = (pred_c).sum()\n",
    "\n",
    "    if (labels_c_sum > 0) or (pred_c_sum > 0):\n",
    "        intersect = np.logical_and(labels_c, pred_c).sum()\n",
    "        union = labels_c_sum + pred_c_sum - intersect\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            return (intersect / union)\n",
    "    return 0 \n",
    "\n",
    "def get_miou(true_label, predict_label, number_classes):\n",
    "    # get the miou of single image\n",
    "    \n",
    "    # both should be 2 dim\n",
    "    conf_matrix = confusion_matrix(x=predict_label, \n",
    "                                   y=true_label, \n",
    "                                   n=number_classes)\n",
    "    \n",
    "    iou_arr = getIoU(conf_matrix)\n",
    "    \n",
    "    return np.nanmean(iou_arr[1:])\n",
    "\n",
    "def get_cof_arr(true_label, predict_label, number_classes):\n",
    "    # get the miou of single image\n",
    "    \n",
    "    # both should be 2 dim\n",
    "    conf_matrix = confusion_matrix(x=predict_label, \n",
    "                                   y=true_label, \n",
    "                                   n=number_classes)\n",
    "    \n",
    "    iou_arr = getIoU(conf_matrix)\n",
    "    \n",
    "    return conf_matrix, iou_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9024b7e9-20a1-4c1e-807c-220a504035ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model_one_image(model_fn, big_image_path_fn, big_image_shape,\n",
    "                            image_size=512,\n",
    "                            add_filter_channel=False,\n",
    "                            intensity_correction=0.0,\n",
    "                            median_after_segmentation=True\n",
    "                           ):\n",
    "    \n",
    "    big_image_name = os.path.split(big_image_path_fn)[-1]\n",
    "\n",
    "    images = divide_image(big_image_path_fn, big_image_path_fn, \n",
    "                              image_size=image_size, do_crop=False,\n",
    "                              do_overlap=False)\n",
    "    # Make predictions\n",
    "    for image in images:\n",
    "        data = model_utils.convert_training_images_to_numpy_arrays([image],\n",
    "                                                       add_filter_channel=add_filter_channel)[\n",
    "            0]\n",
    "        data += intensity_correction / (2 ** 8 - 1)\n",
    "        if not add_filter_channel and data.shape[-1] != 3:\n",
    "            # print('add filter channel')\n",
    "            data = model_utils.fake_colors(data)\n",
    "        prediction = model_fn.predict(data)\n",
    "        prediction = np.argmax(prediction, axis=-1)\n",
    "        prediction = np.squeeze(prediction)\n",
    "        image.labels = prediction\n",
    "    \n",
    "    big_image_array = reassemble_big_image(images, small_image_size=image_size,\n",
    "                                        big_image_shape=big_image_shape)\n",
    "\n",
    "    if median_after_segmentation:\n",
    "        big_image_array = image_processing_utils.median_filter(\n",
    "            image=big_image_array, kernel_size=7)\n",
    "        \n",
    "    return big_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ef1f00-759f-4987-9d31-e6f2666fd9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the conf matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8768ea-ef9f-4c98-aaf1-8fe23c880347",
   "metadata": {},
   "source": [
    "use this one for actual test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849bc9fd-43f0-4791-96c6-590cc3e93007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_miou_magnet_conf(predict_path, dataset_path,\n",
    "                               number_classes=6, median_after_segmentation=True,\n",
    "                               verbose=0):\n",
    "    # first predicts each image and adds the miou to the list, then averages the means\n",
    "    # loops through all the images\n",
    "\n",
    "    miou_list = []\n",
    "    conf_list = []\n",
    "    miou_arr_list = []\n",
    "\n",
    "    # load images\n",
    "    img_paths = glob.glob(os.path.join(dataset_path, 'image', '*.tif'))\n",
    "    lbl_paths = glob.glob(os.path.join(dataset_path, 'label', '*.tif'))\n",
    "    pred_paths = glob.glob(os.path.join(predict_path, '*.png'))\n",
    "\n",
    "    img_paths.sort()\n",
    "    lbl_paths.sort()\n",
    "    pred_paths.sort()\n",
    "\n",
    "    print(pred_paths)\n",
    "\n",
    "    for idx, img in enumerate(img_paths):\n",
    "\n",
    "        print(f'working on image {os.path.split(img_paths[idx])[-1]}')\n",
    "        assert os.path.split(\n",
    "            img_paths[idx])[-1] == os.path.split(lbl_paths[idx])[-1]\n",
    "\n",
    "        assert os.path.split(\n",
    "            pred_paths[idx])[-1].replace('png', 'tif') == os.path.split(lbl_paths[idx])[-1]\n",
    "\n",
    "        test_label_path = lbl_paths[idx]\n",
    "        test_predict_path = pred_paths[idx]\n",
    "\n",
    "        # get the ground truth\n",
    "        label_matrix = gdal_utils.read_tiff_file(large_image_path=test_label_path,\n",
    "                                                 normalize=False,\n",
    "                                                 zeropadsize=None,\n",
    "                                                 numpy_array_only=True,\n",
    "                                                 grayscale_only=False)\n",
    "\n",
    "        prediction_matrix = image_processing_utils.read_png_file(\n",
    "            image_path=test_predict_path,)\n",
    "\n",
    "        # get the miou of single image\n",
    "        if label_matrix.ndim > 2:\n",
    "            label_matrix = label_matrix[:, :, 0]\n",
    "        # get the miou of single image\n",
    "        if prediction_matrix.ndim > 2:\n",
    "            prediction_matrix = prediction_matrix[:, :, 0]\n",
    "        \n",
    "        # get conf matrix \n",
    "        conf, miou_arr = get_cof_arr(true_label=label_matrix, \n",
    "                                     predict_label=prediction_matrix, \n",
    "                                     number_classes=number_classes)\n",
    "        \n",
    "        miou = get_miou(true_label=label_matrix,\n",
    "                        predict_label=prediction_matrix,\n",
    "                        number_classes=number_classes)\n",
    "        \n",
    "        if verbose == 1:\n",
    "            print(f'miou is {miou}')\n",
    "\n",
    "        miou_list.append(miou)\n",
    "        miou_arr_list.append(miou_arr)\n",
    "        conf_list.append(conf)\n",
    "    \n",
    "    # get the miou arr for each test set\n",
    "    miou_arr_np = np.stack(miou_arr_list)\n",
    "    miou_arr_avg = miou_arr_np.mean(axis=0)\n",
    "    \n",
    "    # get the confusion matrix\n",
    "    conf_mat_np = np.stack(conf_list).sum(axis=0)\n",
    "    conf_mat_df = pd.DataFrame(conf_mat_np)\n",
    "\n",
    "    conf_mat_df = conf_mat_df.rename(columns={0:'U', 1:'G', 2:'V', 3:'F', 4:'A', 5:'W'}, \n",
    "              index={0:'U', 1:'G', 2:'V', 3:'F', 4:'A', 5:'W'})\n",
    "    conf_mat_df = conf_mat_df.div(conf_mat_df.sum(axis=1), axis=0).round(4)\n",
    "    \n",
    "    \n",
    "    return np.stack(miou_list).mean(), miou_list, miou_arr_avg, conf_mat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3201f1e7-bdf6-45c1-a300-b2373f0f3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_miou_predict_conf(model_path, dataset_path,\n",
    "                                image_size=512, number_classes=6,\n",
    "                                median_after_segmentation=True, verbose=0):\n",
    "    # first predicts each image and adds the miou to the list, then averages the means\n",
    "    # loops through all the images\n",
    "\n",
    "    have_lr_scheduler = True\n",
    "    miou_list = []\n",
    "    conf_list = []\n",
    "    miou_arr_list = []\n",
    "\n",
    "    # load the model\n",
    "    model = model_utils.load_model(\n",
    "        model_path, have_lr_scheduler=have_lr_scheduler)\n",
    "\n",
    "    # load images\n",
    "    img_paths = glob.glob(os.path.join(dataset_path, 'image', '*.tif'))\n",
    "    lbl_paths = glob.glob(os.path.join(dataset_path, 'label', '*.tif'))\n",
    "\n",
    "    for idx, img in enumerate(img_paths):\n",
    "\n",
    "        print(f'working on image {os.path.split(img_paths[idx])[-1]}')\n",
    "        assert os.path.split(\n",
    "            img_paths[idx])[-1] == os.path.split(lbl_paths[idx])[-1]\n",
    "\n",
    "        test_image_path = img_paths[idx]\n",
    "        test_label_path = lbl_paths[idx]\n",
    "\n",
    "        # get the ground truth\n",
    "        label_matrix = gdal_utils.read_tiff_file(large_image_path=test_label_path,\n",
    "                                                 normalize=False,\n",
    "                                                 zeropadsize=None,\n",
    "                                                 numpy_array_only=True,\n",
    "                                                 grayscale_only=False)\n",
    "\n",
    "        # get the prediction\n",
    "        prediction_matrix = predict_model_one_image(model_fn=model,\n",
    "                                                    big_image_path_fn=test_image_path,\n",
    "                                                    image_size=512,\n",
    "                                                    big_image_shape=(\n",
    "                                                        label_matrix.shape[0], label_matrix.shape[1]),\n",
    "                                                    median_after_segmentation=True,)\n",
    "\n",
    "        # get the miou of single image\n",
    "        if label_matrix.ndim > 2:\n",
    "            label_matrix = label_matrix[:, :, 0]\n",
    "        # get the miou of single image\n",
    "        if prediction_matrix.ndim > 2:\n",
    "            prediction_matrix = prediction_matrix[:, :, 0]\n",
    "        \n",
    "        # get conf matrix \n",
    "        conf, miou_arr = get_cof_arr(true_label=label_matrix, \n",
    "                                     predict_label=prediction_matrix, \n",
    "                                     number_classes=number_classes)\n",
    "        \n",
    "        miou = get_miou(true_label=label_matrix,\n",
    "                        predict_label=prediction_matrix,\n",
    "                        number_classes=number_classes)\n",
    "        \n",
    "        if verbose == 1:\n",
    "            print(f'miou is {miou}')\n",
    "\n",
    "        miou_list.append(miou)\n",
    "        miou_arr_list.append(miou_arr)\n",
    "        conf_list.append(conf)\n",
    "    \n",
    "    # get the miou arr for each test set\n",
    "    miou_arr_np = np.stack(miou_arr_list)\n",
    "    miou_arr_avg = miou_arr_np.mean(axis=0)\n",
    "    \n",
    "    # get the confusion matrix\n",
    "    conf_mat_np = np.stack(conf_list).sum(axis=0)\n",
    "    conf_mat_df = pd.DataFrame(conf_mat_np)\n",
    "\n",
    "    conf_mat_df = conf_mat_df.rename(columns={0:'U', 1:'G', 2:'V', 3:'F', 4:'A', 5:'W'}, \n",
    "              index={0:'U', 1:'G', 2:'V', 3:'F', 4:'A', 5:'W'})\n",
    "    conf_mat_df = conf_mat_df.div(conf_mat_df.sum(axis=1), axis=0).round(4)\n",
    "    \n",
    "    \n",
    "    return np.stack(miou_list).mean(), miou_list, miou_arr_avg, conf_mat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7514a9-c113-4c44-9538-952eeb13fb80",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Get the test MIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "862d26d0-0b38-4750-9e52-7aea28919275",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_path = '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet'\n",
    "testset_path = '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/all_test_tif/TestSet/tif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b8a5422-9514-4eaa-b090-156aa08152d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet/33-2-436-165-31.png', '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet/33-2-436-165-32.png', '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet/33-2-437-165-02.png', '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet/33-2-450-207-03.png', '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet/33-2-462-210-33.png', '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet/33-2-462-211-30.png', '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet/33-2-463-211-00.png', '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet/33-2-463-211-01.png', '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet/33-2-463-211-02.png', '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet/33-2-463-212-00.png', '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet/33-2-466-205-02.png', '/home/saeid/phd/segmentation/dataset/neurips dataset/dataset_division/magnet_prediction/TestSet/33-2-469-211-20.png']\n",
      "working on image 33-2-436-165-31.tif\n",
      "miou is 0.3928925493317413\n",
      "working on image 33-2-436-165-32.tif\n",
      "miou is 0.49054915788028\n",
      "working on image 33-2-437-165-02.tif\n",
      "miou is 0.5224083321577064\n",
      "working on image 33-2-450-207-03.tif\n",
      "miou is 0.35553285472726726\n",
      "working on image 33-2-462-210-33.tif\n",
      "miou is 0.7391123827871073\n",
      "working on image 33-2-462-211-30.tif\n",
      "miou is 0.6182572313812431\n",
      "working on image 33-2-463-211-00.tif\n",
      "miou is 0.7089572535231706\n",
      "working on image 33-2-463-211-01.tif\n",
      "miou is 0.7517108057551953\n",
      "working on image 33-2-463-211-02.tif\n",
      "miou is 0.6693585372300631\n",
      "working on image 33-2-463-212-00.tif\n",
      "miou is 0.733890093426035\n",
      "working on image 33-2-466-205-02.tif\n",
      "miou is 0.5708593485229766\n",
      "working on image 33-2-469-211-20.tif\n",
      "miou is 0.6355691712864326\n"
     ]
    }
   ],
   "source": [
    "min_miou, miou_tmp, arr_tmp, conf_tmp = calculate_test_miou_magnet_conf(\n",
    "        predict_path=prediction_path,\n",
    "        dataset_path=testset_path,\n",
    "        number_classes=6, median_after_segmentation=True,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d3d0c7e-aecf-4c4e-926c-c0057a19a22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U</th>\n",
       "      <th>G</th>\n",
       "      <th>V</th>\n",
       "      <th>F</th>\n",
       "      <th>A</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.2318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7481</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0814</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.2296</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>0.7019</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.1889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        U       G       V       F       A       W\n",
       "U  0.6888  0.0009  0.0440  0.0294  0.0050  0.2318\n",
       "G  0.0000  0.7481  0.0895  0.0814  0.0131  0.0678\n",
       "V  0.0019  0.0060  0.9172  0.0563  0.0102  0.0084\n",
       "F  0.0000  0.0012  0.0566  0.9142  0.0184  0.0096\n",
       "A  0.0004  0.0190  0.0636  0.2296  0.6861  0.0013\n",
       "W  0.7019  0.0073  0.0663  0.0316  0.0039  0.1889"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46015e1a-1e3f-47fd-b5a7-9b729e140002",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get the test set statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f41af1f-7774-4d99-8e71-5f96d0f9af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iou_to_np(iou_path):\n",
    "    places = []\n",
    "\n",
    "    # open file and read the content in a list\n",
    "    with open(iou_path, 'r') as filehandle:\n",
    "        for line in filehandle:\n",
    "            # remove linebreak which is the last character of the string\n",
    "            currentPlace = line[:-1]\n",
    "\n",
    "            # add item to the list\n",
    "            places.append(currentPlace)\n",
    "\n",
    "        return np.array(places[0].replace('[', '').replace('  ', ' ').split(' ')).astype(np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95e57ed8-3b49-43d4-87ba-bb3f24963559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the iou of each class of all five experimets\n",
    "base_path = '/home/saeid/phd/segmentation/dataset/neurips dataset/results/time5/OOD_no_filter'\n",
    "\n",
    "unet_model_name = '2022-06-05_14:38:03.232252_unet_resnet50_freeze_0'\n",
    "\n",
    "fpn_model_name = '2022-06-06_12:40:05.332701_fpn_resnet50_freeze_0'\n",
    "\n",
    "deep_model_name = '2022-06-07_08:32:05.713270_deeplabv3_resnet50_freeze_0'\n",
    "\n",
    "magnet_model_name = 'magnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f09e441-0a17-4282-b73a-d0ec3af037fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_exp = 10\n",
    "unet_iou_class_path = [os.path.join(base_path, unet_model_name ,f'{unet_model_name}_{rep}_arr.txt') for rep in range(no_exp)]\n",
    "unet_miou_path = [os.path.join(base_path, unet_model_name, f'{unet_model_name}_{rep}.txt') for rep in range(no_exp)]\n",
    "\n",
    "deep_iou_class_path = [os.path.join(base_path, deep_model_name, f'{deep_model_name}_{rep}_arr.txt') for rep in range(no_exp)]\n",
    "deep_miou_path = [os.path.join(base_path, deep_model_name, f'{deep_model_name}_{rep}.txt') for rep in range(no_exp)]\n",
    "\n",
    "fpn_iou_class_path = [os.path.join(base_path, fpn_model_name, f'{fpn_model_name}_{rep}_arr.txt') for rep in range(no_exp)]\n",
    "fpn_miou_path = [os.path.join(base_path, fpn_model_name, f'{fpn_model_name}_{rep}.txt') for rep in range(no_exp)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec72f2-7059-49d6-ad2e-25a7f7189e53",
   "metadata": {},
   "source": [
    "### IOU class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c516be9-75fa-4c2c-9ae7-e57f41fbeb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the iou as numpy array [exp, iou]\n",
    "unet_iou = np.stack([read_iou_to_np(iou) for iou in unet_iou_class_path], axis=0)\n",
    "\n",
    "fpn_iou = np.stack([read_iou_to_np(iou) for iou in fpn_iou_class_path], axis=0)\n",
    "\n",
    "deep_iou = np.stack([read_iou_to_np(iou) for iou in deep_iou_class_path], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff201d7-fb81-4738-8cf8-375cbb1db489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "775961b6-b900-4205-a0ac-d5060755697d",
   "metadata": {},
   "source": [
    "### MIOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e7bff5a9-8e09-4d8f-b17a-2988263965de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the iou as numpy array [exp, iou]\n",
    "unet_miou = np.stack([np.genfromtxt(iou) for iou in unet_miou_path], axis=0)\n",
    "\n",
    "fpn_miou = np.stack([np.genfromtxt(iou) for iou in fpn_miou_path], axis=0)\n",
    "\n",
    "deep_miou = np.stack([np.genfromtxt(iou) for iou in deep_miou_path], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c654745-f196-4bea-af19-52a6a875e5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_miou.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a465e-0613-4db4-a235-c11f8ff93cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
